# streamlit_app.py: Simple web-based user interface for the PDF chatbot using Streamlit
# The UI allows users to ask questions about a PDF document and get answers generated by a local LLM (via Ollama) - combined with RAG.

import streamlit as st
from chatbot_core import build_qa_chain #Imports the function that builds the RAG pipeline.

st.set_page_config(page_title="📄 PDF-Chatbot", layout="wide") #To set up the Sreamlit page with a title & wide layout
st.title("📄 Chat with your PDF")

qa_chain = build_qa_chain("AGI.pdf") #Builds the QA chain using the specified PDF file

#Initializes the chat history in Streamlit's session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  

# Creates a text input field for the user to ask a question
question = st.text_input("What would you like to know?", key="input")

#If a question is submitted, the question is sent to the QA chain & stores the result
if question:
    result = qa_chain({
        "question": question,
        "chat_history": st.session_state.chat_history
    })

    st.session_state.chat_history.append((question, result["answer"])) #Saves the question & the answer to the session history

    # Displays the chat history in reverse order (newest on top)
    for i, (q, a) in enumerate(st.session_state.chat_history[::-1]):
        st.markdown(f"**❓ Question {len(st.session_state.chat_history) - i}:** {q}")
        st.markdown(f"**🤖 Answer:** {a}")