from chatbot_core import build_qa_chain # Imports the RAG pipeline builder from chatbot_core.py

qa_chain = build_qa_chain("/Users/braintip/AIBOOKCLUB/AGI.pdf") #Builds the QA chain using a local PDF file
chat_history = [] #Initializes an empty list to store the chat history

print("ğŸ§  PDF-Chatbot started! Enter 'exit' to quit.") # Prints the welcome message to the terminal

# Starts a loop to allow the user to ask questions continuously
while True:
    query = input("\nâ“ Your questions: ")
    # Breaks the loop if the user types 'exit' or 'quit'
    if query.lower() in ["exit", "quit"]:
        print("ğŸ‘‹ Chat finished.")
        break

    # Get the answer from the QA chain (LLM + Retriever) and prints the answer to the terminal
    result = qa_chain({"question": query, "chat_history": chat_history})
    print("\nğŸ’¬ Answer:", result["answer"])
    chat_history.append((query, result["answer"])) #Saves the Q&A pair in the chat history
    print("\nğŸ” Source â€“ Document snippet:") #Shows a snippet from the source document that is used
    print(result["source_documents"][0].page_content[:300])